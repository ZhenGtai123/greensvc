{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","source":["# ğŸŒ¿ GreenSVC-AI Stage 1: Evidence-Based Indicator Matching\n","\n","**Required Files**:\n","- `Evidence_final_v5_2_fixed.json` - Research evidence records\n","- `Appendix_final_v5_2_fixed.json` - Codebook (code definitions)\n","\n","**Output**: Recommended indicators with evidence support"],"metadata":{"id":"header"}},{"cell_type":"markdown","source":["## 1. Environment Setup"],"metadata":{"id":"s1"}},{"cell_type":"code","source":["!pip install -q google-generativeai"],"metadata":{"id":"install"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os, json, re\n","from pathlib import Path\n","from datetime import datetime\n","from collections import defaultdict\n","from google.colab import drive, userdata, files\n","import google.generativeai as genai\n","print(\"âœ… Libraries imported successfully\")"],"metadata":{"id":"imports","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1766626402199,"user_tz":-60,"elapsed":9826,"user":{"displayName":"junkai lan","userId":"05837454952170495153"}},"outputId":"cc00bc1b-611a-4577-9045-93cec1cb940b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Libraries imported successfully\n"]}]},{"cell_type":"code","source":["drive.mount('/content/drive')\n","print(\"âœ… Google Drive mounted\")"],"metadata":{"id":"mount","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1766626496827,"user_tz":-60,"elapsed":16770,"user":{"displayName":"junkai lan","userId":"05837454952170495153"}},"outputId":"2e2c9aa8-7736-478a-fc99-d35afa432ff1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","âœ… Google Drive mounted\n"]}]},{"cell_type":"code","source":["try:\n","    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n","    print(\"âœ… API Key retrieved from Secrets\")\n","except:\n","    GOOGLE_API_KEY = input(\"Enter Google API Key: \")\n","genai.configure(api_key=GOOGLE_API_KEY)"],"metadata":{"id":"api"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. Configuration"],"metadata":{"id":"s2"}},{"cell_type":"code","source":["CONFIG = {\n","    # å¿…éœ€æ–‡ä»¶\n","    \"evidence_path\": \"/content/drive/MyDrive/GreenSVC-AI-paper/KnowledgeBase/Evidence_final_v5_2_fixed.json\",\n","    \"appendix_path\": \"/content/drive/MyDrive/GreenSVC-AI-paper/KnowledgeBase/Appendix_final_v5_2_fixed.json\",\n","\n","    # ç”¨æˆ·é—®å·\n","    \"user_query_path\": \"/content/drive/MyDrive/GreenSVC-AI-paper/UserQueries/GreenSVC-AI_mock_filled_query_single_performance_photos_45_per_zone.json\",\n","\n","    # è¾“å‡º\n","    \"output_path\": \"/content/drive/MyDrive/GreenSVC-AI-paper/Outputs\",\n","\n","    # æ¨¡å‹\n","    \"model_name\": \"gemini-3-pro-preview\",\n","    \"max_codebook_chars\": 40000,\n","}\n","print(f\"âš™ï¸ Model: {CONFIG['model_name']}\")"],"metadata":{"id":"config","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1766624312156,"user_tz":-60,"elapsed":12,"user":{"displayName":"junkai lan","userId":"05837454952170495153"}},"outputId":"1449b5ca-2507-4fb6-b068-77c1492291b7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âš™ï¸ Model: gemini-3-pro-preview\n"]}]},{"cell_type":"markdown","source":["## 3. Load Data"],"metadata":{"id":"s3"}},{"cell_type":"code","source":["class KnowledgeBase:\n","    \"\"\"åŠ è½½å’Œç´¢å¼•Evidenceæ•°æ®\"\"\"\n","\n","    def __init__(self, evidence_path):\n","        self.evidence = []\n","        self.perf_idx = defaultdict(list)      # æŒ‰dimensionç´¢å¼•\n","        self.subdim_idx = defaultdict(list)    # æŒ‰subdimensionç´¢å¼•\n","\n","        if Path(evidence_path).exists():\n","            self.evidence = json.load(open(evidence_path, encoding='utf-8'))\n","            print(f\"ğŸ“š Evidence loaded: {len(self.evidence)} records\")\n","            self._build_index()\n","\n","    def _build_index(self):\n","        \"\"\"æ„å»ºç´¢å¼•\"\"\"\n","        for e in self.evidence:\n","            perf = e.get('performance', {})\n","            dim = perf.get('dimension_id')\n","            subdim = perf.get('subdimension_id')\n","\n","            if dim:\n","                self.perf_idx[dim].append(e)\n","            if subdim and subdim != 'PRS_NA':\n","                self.subdim_idx[subdim].append(e)\n","\n","        print(f\"   Index: {len(self.perf_idx)} dimensions, {len(self.subdim_idx)} subdimensions\")\n","\n","    def retrieve(self, dimensions, subdimensions=None):\n","        \"\"\"æ ¹æ®dimensionså’Œsubdimensionsæ£€ç´¢ç›¸å…³Evidence\"\"\"\n","        evds = []\n","\n","        # æŒ‰dimensionæ£€ç´¢\n","        for d in dimensions:\n","            for e in self.perf_idx.get(d, []):\n","                if e not in evds:\n","                    evds.append(e)\n","\n","        # æŒ‰subdimensionè¡¥å……æ£€ç´¢\n","        if subdimensions:\n","            for sd in subdimensions:\n","                for e in self.subdim_idx.get(sd, []):\n","                    if e not in evds:\n","                        evds.append(e)\n","\n","        print(f\"ğŸ” Retrieved: {len(evds)} Evidence records\")\n","        return evds\n","\n","kb = KnowledgeBase(CONFIG['evidence_path'])"],"metadata":{"id":"kb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1766624315720,"user_tz":-60,"elapsed":22,"user":{"displayName":"junkai lan","userId":"05837454952170495153"}},"outputId":"6885f335-d289-4994-e30c-95facccbdf4c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ“š Evidence loaded: 320 records\n","   Index: 8 dimensions, 53 subdimensions\n"]}]},{"cell_type":"code","source":["class Codebook:\n","    \"\"\"åŠ è½½Appendixä»£ç æœ¬\"\"\"\n","\n","    def __init__(self, path):\n","        self.data = {}\n","        if Path(path).exists():\n","            self.data = json.load(open(path, encoding='utf-8'))\n","            print(f\"ğŸ“– Codebook loaded: {len(self.data)} tables\")\n","\n","    def subset(self, max_chars=40000):\n","        \"\"\"æå–ç”¨äºpromptçš„å­é›†\"\"\"\n","        priority = [\n","            'A_indicators', 'A_categories',\n","            'C_performance', 'C_subdimensions', 'C_outcome_types',\n","            'B_methods', 'B_units', 'B_data_sources',\n","            'D_directions', 'D_significance',\n","            'E_settings', 'E_countries',\n","            'K_climate', 'F_quality'\n","        ]\n","        out, sz = {}, 0\n","        for n in priority:\n","            if n in self.data:\n","                simplified = {}\n","                for code, entry in self.data[n].items():\n","                    simplified[code] = {\n","                        \"name\": entry.get('name', code),\n","                        \"definition\": entry.get('definition', '')[:200]\n","                    }\n","                s = len(json.dumps(simplified, ensure_ascii=False))\n","                if sz + s < max_chars:\n","                    out[n] = simplified\n","                    sz += s\n","        return out\n","\n","codebook = Codebook(CONFIG['appendix_path'])"],"metadata":{"id":"cb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1766624319066,"user_tz":-60,"elapsed":48,"user":{"displayName":"junkai lan","userId":"05837454952170495153"}},"outputId":"e8d65ebd-4059-4b52-f7ed-21434b842c11"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ“– Codebook loaded: 34 tables\n"]}]},{"cell_type":"code","source":["qpath = Path(CONFIG['user_query_path'])\n","if qpath.exists():\n","    USER_QUERY = json.load(open(qpath, encoding='utf-8'))\n","    print(f\"âœ… Loaded: {qpath.name}\")\n","else:\n","    print(\"ğŸ“¤ Please upload user query JSON:\")\n","    up = files.upload()\n","    USER_QUERY = json.loads(list(up.values())[0].decode('utf-8'))\n","\n","# æ˜¾ç¤ºé¡¹ç›®ä¿¡æ¯\n","print(f\"ğŸ“‹ Project: {USER_QUERY.get('project', {}).get('name', 'N/A')}\")\n","print(f\"   Location: {USER_QUERY.get('project', {}).get('location', 'N/A')}\")\n","print(f\"   Scale: {USER_QUERY.get('project', {}).get('scale', 'N/A')}\")\n","print(f\"   Phase: {USER_QUERY.get('project', {}).get('phase', 'N/A')}\")\n","\n","# æ˜¾ç¤ºæ€§èƒ½æŸ¥è¯¢ä¿¡æ¯\n","perf_query = USER_QUERY.get('performance_query', {})\n","print(f\"\\nğŸ¯ Performance Query:\")\n","print(f\"   Dimensions: {perf_query.get('dimensions', [])}\")\n","print(f\"   Subdimensions: {perf_query.get('subdimensions', [])}\")\n","\n","# æ˜¾ç¤ºç©ºé—´åŒºåŸŸä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰\n","zones = USER_QUERY.get('spatial_zones', [])\n","if zones:\n","    print(f\"\\nğŸ—ºï¸ Spatial Zones ({len(zones)}):\")\n","    for z in zones:\n","        print(f\"   â€¢ {z.get('zone_id')}: {z.get('zone_name')} ({z.get('status', 'N/A')})\")"],"metadata":{"id":"query","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1766624321246,"user_tz":-60,"elapsed":19,"user":{"displayName":"junkai lan","userId":"05837454952170495153"}},"outputId":"2d501cb3-5e5b-45f0-c152-451ea6c72a40"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Loaded: GreenSVC-AI_mock_filled_query_single_performance_photos_45_per_zone.json\n","ğŸ“‹ Project: Amsterdam Pocket Park Retrofit (Oost District)\n","   Location: Amsterdam, Netherlands (Oost district, near Oosterpark)\n","   Scale: S\n","   Phase: renovation\n","\n","ğŸ¯ Performance Query:\n","   Dimensions: ['PRF_BEH']\n","   Subdimensions: ['PRS_WLK', 'PRS_NAV']\n","\n","ğŸ—ºï¸ Spatial Zones (6):\n","   â€¢ zone_0: North Entrance Forecourt (moderate)\n","   â€¢ zone_1: Central Multi-use Lawn (good)\n","   â€¢ zone_2: Family Play Pocket (poor)\n","   â€¢ zone_3: Woodland Edge Loop Path (poor)\n","   â€¢ zone_4: Waterfront Deck & Seating (critical)\n","   â€¢ zone_5: Service Node (Toilet/Kiosk) (moderate)\n"]}]},{"cell_type":"markdown","source":["## 4. Retrieve & Build Prompt"],"metadata":{"id":"s4"}},{"cell_type":"code","source":["# è·å–dimensionså’Œsubdimensions\n","perf_query = USER_QUERY.get('performance_query', {})\n","dims = perf_query.get('dimensions', [])\n","subdims = perf_query.get('subdimensions', [])\n","\n","print(f\"ğŸ¯ Target dimensions: {dims}\")\n","print(f\"ğŸ¯ Target subdimensions: {subdims}\")\n","\n","# æ£€ç´¢ç›¸å…³è¯æ®\n","matched_evd = kb.retrieve(dims, subdims)\n","\n","# è·å–Codebookå­é›†\n","cb_subset = codebook.subset(CONFIG['max_codebook_chars'])\n","print(f\"ğŸ“– Codebook subset: {len(cb_subset)} tables\")"],"metadata":{"id":"retrieve","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1766624323646,"user_tz":-60,"elapsed":20,"user":{"displayName":"junkai lan","userId":"05837454952170495153"}},"outputId":"76135492-86c3-4dde-cf4f-ee5370bcb0cd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ¯ Target dimensions: ['PRF_BEH']\n","ğŸ¯ Target subdimensions: ['PRS_WLK', 'PRS_NAV']\n","ğŸ” Retrieved: 66 Evidence records\n","ğŸ“– Codebook subset: 8 tables\n"]}]},{"cell_type":"code","source":["PROMPT_TEMPLATE = \"\"\"\n","# GreenSVC-AI Stage 1: Evidence-Based Indicator Matching\n","\n","## System Role\n","You are an evidence-based landscape design consultant. Your task is to recommend environmental indicators for landscape projects based on scientific evidence.\n","\n","## Core Principles\n","1. **Evidence-Based**: Every recommendation must cite evidence_id\n","2. **Code Expansion**: Use Codebook to expand all codes to code + name + definition\n","3. **No Fabrication**: Only use evidence that exists in the input\n","\n","---\n","\n","## Input Data\n","\n","### User Query\n","```json\n","{query}\n","```\n","\n","### Codebook (Code Definitions)\n","```json\n","{codebook}\n","```\n","\n","### Evidence ({evd_count} records)\n","```json\n","{evidence}\n","```\n","\n","---\n","\n","## Output Format\n","\n","Output a JSON object with this structure:\n","\n","```json\n","{{\n","  \"metadata\": {{\n","    \"project_name\": \"from query.project.name\",\n","    \"target_dimensions\": [{{\"code\": \"PRF_BEH\", \"name\": \"...\", \"definition\": \"...\"}}],\n","    \"target_subdimensions\": [{{\"code\": \"PRS_WLK\", \"name\": \"...\", \"definition\": \"...\"}}],\n","    \"evidence_used\": 10\n","  }},\n","\n","  \"recommended_indicators\": [\n","    {{\n","      \"rank\": 1,\n","      \"indicator\": {{\n","        \"code\": \"IND_XXX\",\n","        \"name\": \"from Codebook\",\n","        \"definition\": \"from Codebook\",\n","        \"formula\": \"from Evidence\",\n","        \"category\": {{\"code\": \"CAT_XXX\", \"name\": \"...\", \"definition\": \"...\"}}\n","      }},\n","      \"performance\": {{\n","        \"dimension\": {{\"code\": \"PRF_BEH\", \"name\": \"...\", \"definition\": \"...\"}},\n","        \"subdimension\": {{\"code\": \"PRS_WLK\", \"name\": \"...\", \"definition\": \"...\"}},\n","        \"outcome_measure\": \"from Evidence\",\n","        \"outcome_type\": {{\"code\": \"OUT_XXX\", \"name\": \"...\", \"definition\": \"...\"}}\n","      }},\n","      \"evidence\": [\n","        {{\n","          \"evidence_id\": \"EVD_xxx\",\n","          \"citation\": \"Author (Year). Title.\",\n","          \"year\": 2024,\n","          \"doi\": \"10.xxx\",\n","          \"relationship\": {{\n","            \"direction\": {{\"code\": \"DIR_POS\", \"name\": \"Positive\", \"definition\": \"...\"}},\n","            \"effect_size\": \"0.45\",\n","            \"p_value\": \"<0.001\",\n","            \"significance\": {{\"code\": \"SIG_001\", \"name\": \"...\", \"definition\": \"...\"}}\n","          }},\n","          \"study\": {{\n","            \"design\": {{\"code\": \"DES_CRS\", \"name\": \"...\", \"definition\": \"...\"}},\n","            \"sample_size\": 100,\n","            \"setting\": {{\"code\": \"SET_PRK\", \"name\": \"...\", \"definition\": \"...\"}},\n","            \"country\": {{\"code\": \"CNT_NLD\", \"name\": \"...\", \"definition\": \"...\"}}\n","          }},\n","          \"quality\": {{\n","            \"tier\": {{\"code\": \"TIR_T2\", \"name\": \"...\", \"definition\": \"...\"}},\n","            \"confidence\": {{\"code\": \"CON_HIG\", \"name\": \"...\", \"definition\": \"...\"}}\n","          }}\n","        }}\n","      ],\n","      \"measurement\": {{\n","        \"method\": {{\"code\": \"MTH_XXX\", \"name\": \"...\", \"definition\": \"...\"}},\n","        \"unit\": {{\"code\": \"UNT_XXX\", \"name\": \"...\", \"definition\": \"...\"}},\n","        \"data_source\": {{\"code\": \"SRC_XXX\", \"name\": \"...\", \"definition\": \"...\"}}\n","      }},\n","      \"target_direction\": {{\n","        \"direction\": \"INCREASE or DECREASE\",\n","        \"derivation\": \"Based on evidence direction and performance goal\"\n","      }},\n","      \"rationale\": \"Why this indicator is recommended\"\n","    }}\n","  ],\n","\n","  \"indicator_relationships\": [\n","    {{\n","      \"indicators\": [{{\"code\": \"IND_A\", \"name\": \"...\"}}, {{\"code\": \"IND_B\", \"name\": \"...\"}}],\n","      \"type\": \"SYNERGISTIC/INVERSE/INDEPENDENT\",\n","      \"explanation\": \"How they interact\"\n","    }}\n","  ],\n","\n","  \"summary\": {{\n","    \"total_indicators\": 5,\n","    \"total_evidence\": 12,\n","    \"key_findings\": [\"Finding 1\", \"Finding 2\"],\n","    \"evidence_gaps\": [\"Gap 1\"]\n","  }}\n","}}\n","```\n","\n","## Rules\n","1. Recommend 5-8 indicators relevant to target dimensions/subdimensions\n","2. Each indicator MUST have evidence_id from the provided Evidence\n","3. Expand ALL codes using Codebook\n","4. Do NOT output numerical target values\n","5. Output valid JSON directly, no markdown code blocks\n","\"\"\"\n","\n","def build_prompt(query, evidence, cb):\n","    return PROMPT_TEMPLATE.format(\n","        query=json.dumps(query, ensure_ascii=False, indent=2),\n","        codebook=json.dumps(cb, ensure_ascii=False, indent=2),\n","        evidence=json.dumps(evidence[:60], ensure_ascii=False, indent=2),\n","        evd_count=len(evidence)\n","    )\n","\n","prompt = build_prompt(USER_QUERY, matched_evd, cb_subset)\n","print(f\"ğŸ“ Prompt: {len(prompt):,} chars (~{len(prompt)//4:,} tokens)\")"],"metadata":{"id":"prompt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1766624325421,"user_tz":-60,"elapsed":14,"user":{"displayName":"junkai lan","userId":"05837454952170495153"}},"outputId":"53c458a8-ade7-4252-94a6-c5b71286c58f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ“ Prompt: 259,955 chars (~64,988 tokens)\n"]}]},{"cell_type":"markdown","source":["## 5. Call API"],"metadata":{"id":"s5"}},{"cell_type":"code","source":["class Runner:\n","    def __init__(self, model):\n","        self.model = genai.GenerativeModel(model)\n","        print(f\"âœ… Model: {model}\")\n","\n","    def run(self, prompt):\n","        print(f\"ğŸš€ Calling API (~{len(prompt)//4:,} tokens)\")\n","        cfg = genai.GenerationConfig(temperature=0.2, max_output_tokens=32768)\n","        resp = self.model.generate_content(prompt, generation_config=cfg)\n","        text = resp.text\n","        print(f\"âœ… Response: {len(text):,} chars\")\n","        if not text.rstrip().endswith('}'): print(\"âš ï¸ May be truncated\")\n","        return self._parse(text)\n","\n","    def _parse(self, text):\n","        text = text.strip()\n","        for p in ['```json', '```']:\n","            if text.startswith(p): text = text[len(p):]\n","        if text.endswith('```'): text = text[:-3]\n","        text = text.strip()\n","        try: return json.loads(text)\n","        except: pass\n","        if not text.endswith('}'):\n","            r = text.rstrip().rstrip(',: \\n\\t\"')\n","            r += ']' * (text.count('[') - text.count(']'))\n","            r += '}' * (text.count('{') - text.count('}'))\n","            try:\n","                res = json.loads(r)\n","                res['_warning'] = 'Auto-repaired'\n","                return res\n","            except: pass\n","        return {'raw': text, 'error': True}\n","\n","runner = Runner(CONFIG['model_name'])"],"metadata":{"id":"runner","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1766624328702,"user_tz":-60,"elapsed":61,"user":{"displayName":"junkai lan","userId":"05837454952170495153"}},"outputId":"89dcbe2b-0858-4525-b3a4-93bb2ba389ca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Model: gemini-3-pro-preview\n"]}]},{"cell_type":"code","source":["print(\"=\"*60)\n","print(\"ğŸŒ¿ GreenSVC-AI Stage 1\")\n","print(\"=\"*60)\n","result = runner.run(prompt)\n","print(\"=\"*60)"],"metadata":{"id":"run","colab":{"base_uri":"https://localhost:8080/","height":138},"executionInfo":{"status":"ok","timestamp":1766621576603,"user_tz":-60,"elapsed":81523,"user":{"displayName":"junkai lan","userId":"05837454952170495153"}},"outputId":"964c5056-a11e-4cef-b1a7-fe942f403601"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","ğŸŒ¿ GreenSVC-AI Stage 1\n","============================================================\n","ğŸš€ Calling API (~64,988 tokens)\n","âœ… Response: 27,503 chars\n","âš ï¸ May be truncated\n","============================================================\n"]}]},{"cell_type":"markdown","source":["## 6. View Results"],"metadata":{"id":"s6"}},{"cell_type":"code","source":["if 'error' not in result:\n","    if '_warning' in result: print(f\"âš ï¸ {result['_warning']}\")\n","\n","    print(\"\\nğŸ“Š Results Summary\")\n","    print(\"=\"*60)\n","\n","    meta = result.get('metadata', {})\n","    print(f\"Project: {meta.get('project_name', 'N/A')}\")\n","    print(f\"Evidence used: {meta.get('evidence_used', 0)} records\")\n","\n","    # ç›®æ ‡ç»´åº¦\n","    dims = meta.get('target_dimensions', [])\n","    if dims:\n","        print(f\"\\nğŸ¯ Target Dimensions: {[d.get('code') for d in dims]}\")\n","\n","    subdims = meta.get('target_subdimensions', [])\n","    if subdims:\n","        print(f\"ğŸ¯ Target Subdimensions: {[s.get('code') for s in subdims]}\")\n","\n","    # æ¨èæŒ‡æ ‡\n","    inds = result.get('recommended_indicators', [])\n","    print(f\"\\nğŸ¯ Recommended Indicators ({len(inds)}):\")\n","    for ind in inds:\n","        i = ind.get('indicator', {})\n","        td = ind.get('target_direction', {})\n","        evs = ind.get('evidence', [])\n","\n","        print(f\"\\n  {ind.get('rank', '?')}. {i.get('code', 'N/A')} - {i.get('name', 'N/A')}\")\n","        print(f\"     Direction: {td.get('direction', 'N/A')}\")\n","        if evs:\n","            print(f\"     Evidence: {evs[0].get('evidence_id', 'N/A')}\")\n","\n","    # å…³é”®å‘ç°\n","    summary = result.get('summary', {})\n","    findings = summary.get('key_findings', [])\n","    if findings:\n","        print(\"\\nğŸ“ Key Findings:\")\n","        for f in findings[:3]:\n","            print(f\"   â€¢ {f[:80]}...\")\n","\n","else:\n","    print(f\"âŒ Error: {result.get('error', 'Unknown')}\")"],"metadata":{"id":"view","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1766621599374,"user_tz":-60,"elapsed":34,"user":{"displayName":"junkai lan","userId":"05837454952170495153"}},"outputId":"31ef597d-2824-4616-d5f5-85f1896d7582"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","ğŸ“Š Results Summary\n","============================================================\n","Project: Amsterdam Pocket Park Retrofit (Oost District)\n","Evidence used: 7 records\n","\n","ğŸ¯ Target Dimensions: ['PRF_BEH']\n","ğŸ¯ Target Subdimensions: ['PRS_WLK', 'PRS_SAF_VIS']\n","\n","ğŸ¯ Recommended Indicators (5):\n","\n","  1. IND_GVI - Green View Index\n","     Direction: INCREASE\n","     Evidence: EVD_Lu2018_2\n","\n","  2. IND_VAC - Visible Accessibility Index\n","     Direction: INCREASE\n","     Evidence: EVD_Larkin2021_1\n","\n","  3. IND_VPE - Vegetation Permeability Index\n","     Direction: INCREASE\n","     Evidence: EVD_Li2023_2\n","\n","  4. IND_WLK_IDX - Walkability Index (Visual)\n","     Direction: INCREASE\n","     Evidence: EVD_Zhang2024_8\n","\n","  5. IND_SVF - Sky View Factor\n","     Direction: INCREASE\n","     Evidence: EVD_Zou2024_1\n","\n","ğŸ“ Key Findings:\n","   â€¢ Green View Index (GVI) is the strongest predictor for walking behavior and gener...\n","   â€¢ Visible Accessibility (VAC) and Walkability Index (WLK_IDX) are critical for the...\n","   â€¢ Vegetation Permeability (VPE) is a crucial 'check' indicator to ensure the shade...\n"]}]},{"cell_type":"code","source":["print(\"ğŸ“„ Full JSON:\")\n","print(json.dumps(result, ensure_ascii=False, indent=2))"],"metadata":{"id":"full","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1766621603640,"user_tz":-60,"elapsed":17,"user":{"displayName":"junkai lan","userId":"05837454952170495153"}},"outputId":"4a309bfb-ba9c-413e-841e-d2469b3c72db"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ“„ Full JSON:\n","{\n","  \"metadata\": {\n","    \"project_name\": \"Amsterdam Pocket Park Retrofit (Oost District)\",\n","    \"target_dimensions\": [\n","      {\n","        \"code\": \"PRF_BEH\",\n","        \"name\": \"Use, Accessibility & Safety\",\n","        \"definition\": \"Outcomes related to use patterns and behaviors, including functional convenience/accessibility and perceived safety that shape use.\"\n","      }\n","    ],\n","    \"target_subdimensions\": [\n","      {\n","        \"code\": \"PRS_WLK\",\n","        \"name\": \"Walkability Score\",\n","        \"definition\": \"A performance metric assessing the degree to which an environment is friendly to walking. It synthesizes variables such as residential density, intersection connectivity, land-use mix, and safety infrastructure.\"\n","      },\n","      {\n","        \"code\": \"PRS_SAF_VIS\",\n","        \"name\": \"Performance - Visual Safety\",\n","        \"definition\": \"Measures the perception of safety derived specifically from visual cues within an environment. This performance indicator assesses how elements like lighting brightness, sightlines, maintenance levels, and surveillance potential influence a user's sense of security.\"\n","      }\n","    ],\n","    \"evidence_used\": 7\n","  },\n","  \"recommended_indicators\": [\n","    {\n","      \"rank\": 1,\n","      \"indicator\": {\n","        \"code\": \"IND_GVI\",\n","        \"name\": \"Green View Index\",\n","        \"definition\": \"Proportion of green vegetation pixels in street-level imagery\",\n","        \"formula\": \"(Sum(Green_Pixels) / Sum(Total_Pixels)) * 100\",\n","        \"category\": {\n","          \"code\": \"CAT_CMP\",\n","          \"name\": \"Compositional\",\n","          \"definition\": \"Based on element quantity, coverage, proportion\"\n","        }\n","      },\n","      \"performance\": {\n","        \"dimension\": {\n","          \"code\": \"PRF_BEH\",\n","          \"name\": \"Use, Accessibility & Safety\",\n","          \"definition\": \"Outcomes related to use patterns and behaviors, including functional convenience/accessibility and perceived safety that shape use.\"\n","        },\n","        \"subdimension\": {\n","          \"code\": \"PRS_WLK\",\n","          \"name\": \"Walkability Score\",\n","          \"definition\": \"A performance metric assessing the degree to which an environment is friendly to walking.\"\n","        },\n","        \"outcome_measure\": \"Odds of walking (binary decision to walk in last 24h) in 800m buffer\",\n","        \"outcome_type\": {\n","          \"code\": \"OUT_BEH\",\n","          \"name\": \"Behavioral Observation\",\n","          \"definition\": \"OUT_BEH involves the systematic recording of human actions, movements, and usage patterns within a specific setting.\"\n","        }\n","      },\n","      \"evidence\": [\n","        {\n","          \"evidence_id\": \"EVD_Lu2018_2\",\n","          \"citation\": \"Lu, Y. (2018). The Association of Urban Greenness and Walking Behavior: Using Google Street View and Deep Learning Techniques to Estimate Residents' Exposure to Urban Greenness. International Journal of Environmental Research and Public Health, 15(8), 1576.\",\n","          \"year\": 2018,\n","          \"doi\": \"10.3390/ijerph15081576\",\n","          \"relationship\": {\n","            \"direction\": {\n","              \"code\": \"DIR_POS\",\n","              \"name\": \"Positive\",\n","              \"definition\": \"Indicator increase leads to outcome increase\"\n","            },\n","            \"effect_size\": \"1.193\",\n","            \"p_value\": \"0.001\",\n","            \"significance\": {\n","              \"code\": \"SIG_001\",\n","              \"name\": \"p < 0.001\",\n","              \"definition\": \"Highly significant (p < 0.001)\"\n","            }\n","          },\n","          \"study\": {\n","            \"design\": {\n","              \"code\": \"DES_CRS\",\n","              \"name\": \"Cross-Sectional Study\",\n","              \"definition\": \"Observational study analyzing data from a population at a single point in time\"\n","            },\n","            \"sample_size\": 24773,\n","            \"setting\": {\n","              \"code\": \"SET_PUB_HOU\",\n","              \"name\": \"Public Housing\",\n","              \"definition\": \"Public housing estates\"\n","            },\n","            \"country\": {\n","              \"code\": \"CNT_HKG\",\n","              \"name\": \"Hong Kong\",\n","              \"definition\": \"Hong Kong SAR, China\"\n","            }\n","          },\n","          \"quality\": {\n","            \"tier\": {\n","              \"code\": \"TIR_T2\",\n","              \"name\": \"Tier 2: Observational/Correlational\",\n","              \"definition\": \"Evidence derived from cross-sectional or longitudinal studies establishing statistical associations.\"\n","            },\n","            \"confidence\": {\n","              \"code\": \"CON_HIG\",\n","              \"name\": \"High Confidence\",\n","              \"definition\": \"Robust methodology, large sample size, or strong statistical significance.\"\n","            }\n","          }\n","        },\n","        {\n","          \"evidence_id\": \"EVD_Li2015_1\",\n","          \"citation\": \"Li, X., Zhang, C., & Li, W. (2015). Does the Visibility of Greenery Increase Perceived Safety in Urban Areas? Evidence from the Place Pulse 1.0 Dataset. ISPRS International Journal of Geo-Information, 4(3), 1166â€“1183.\",\n","          \"year\": 2015,\n","          \"doi\": \"10.3390/ijgi4031166\",\n","          \"relationship\": {\n","            \"direction\": {\n","              \"code\": \"DIR_POS\",\n","              \"name\": \"Positive\",\n","              \"definition\": \"Indicator increase leads to outcome increase\"\n","            },\n","            \"effect_size\": \"0.388\",\n","            \"p_value\": \"<0.01\",\n","            \"significance\": {\n","              \"code\": \"SIG_001\",\n","              \"name\": \"p < 0.001\",\n","              \"definition\": \"Highly significant (p < 0.001)\"\n","            }\n","          },\n","          \"study\": {\n","            \"design\": {\n","              \"code\": \"DES_CRS\",\n","              \"name\": \"Cross-Sectional Study\",\n","              \"definition\": \"Observational study analyzing data from a population at a single point in time\"\n","            },\n","            \"sample_size\": 1217,\n","            \"setting\": {\n","              \"code\": \"SET_URB\",\n","              \"name\": \"Urban\",\n","              \"definition\": \"General urban environment\"\n","            },\n","            \"country\": {\n","              \"code\": \"CNT_USA\",\n","              \"name\": \"United States\",\n","              \"definition\": \"United States of America\"\n","            }\n","          },\n","          \"quality\": {\n","            \"tier\": {\n","              \"code\": \"TIR_T2\",\n","              \"name\": \"Tier 2: Observational/Correlational\",\n","              \"definition\": \"Evidence derived from cross-sectional or longitudinal studies establishing statistical associations.\"\n","            },\n","            \"confidence\": {\n","              \"code\": \"CON_MED\",\n","              \"name\": \"Medium Confidence\",\n","              \"definition\": \"Acceptable methodology but may have limitations in sample size or generalizability.\"\n","            }\n","          }\n","        }\n","      ],\n","      \"measurement\": {\n","        \"method\": {\n","          \"code\": \"MTH_PSP\",\n","          \"name\": \"PSPNet Segmentation\",\n","          \"definition\": \"Pyramid Scene Parsing Network for semantic segmentation\"\n","        },\n","        \"unit\": {\n","          \"code\": \"UNT_PCT\",\n","          \"name\": \"Percentage\",\n","          \"definition\": \"Proportion expressed as 0-100%\"\n","        },\n","        \"data_source\": {\n","          \"code\": \"SRC_GSV\",\n","          \"name\": \"Google Street View\",\n","          \"definition\": \"Street-level imagery from Google Maps\"\n","        }\n","      },\n","      \"target_direction\": {\n","        \"direction\": \"INCREASE\",\n","        \"derivation\": \"Evidence consistently links higher GVI to increased walking odds and perceived safety, aligning with the goal to improve walkability.\"\n","      },\n","      \"rationale\": \"GVI is the primary indicator for enhancing the 'Woodland Edge Loop Path' and 'Central Multi-use Lawn'. Increasing visible greenery is statistically proven to increase walking frequency and perceived safety, directly addressing the design brief's core target.\"\n","    },\n","    {\n","      \"rank\": 2,\n","      \"indicator\": {\n","        \"code\": \"IND_VAC\",\n","        \"name\": \"Visible Accessibility Index\",\n","        \"definition\": \"The proportion of pixels in a street view image representing accessibility features such as sidewalks, paths, stairs, streetlights, and benches.\",\n","        \"formula\": \"Sum(Pixels_Sidewalk + Pixels_Streetlight + Pixels_Bench) / Total_Pixels\",\n","        \"category\": {\n","          \"code\": \"CAT_CMP\",\n","          \"name\": \"Compositional\",\n","          \"definition\": \"Based on element quantity, coverage, proportion\"\n","        }\n","      },\n","      \"performance\": {\n","        \"dimension\": {\n","          \"code\": \"PRF_BEH\",\n","          \"name\": \"Use, Accessibility & Safety\",\n","          \"definition\": \"Outcomes related to use patterns and behaviors, including functional convenience/accessibility and perceived safety that shape use.\"\n","        },\n","        \"subdimension\": {\n","          \"code\": \"PRS_SAF_VIS\",\n","          \"name\": \"Performance - Visual Safety\",\n","          \"definition\": \"Measures the perception of safety derived specifically from visual cues within an environment.\"\n","        },\n","        \"outcome_measure\": \"TrueSkill Safety Score\",\n","        \"outcome_type\": {\n","          \"code\": \"OUT_SUB\",\n","          \"name\": \"Subjective Rating\",\n","          \"definition\": \"Subjective rating refers to the traditional, human-centric evaluation of 'visual perception' and 'perceived safety.'\"\n","        }\n","      },\n","      \"evidence\": [\n","        {\n","          \"evidence_id\": \"EVD_Larkin2021_1\",\n","          \"citation\": \"Larkin, A., Gu, X., Chen, L., & Hystad, P. (2021). Predicting perceptions of the built environment using GIS, satellite and street view image approaches. Landscape and Urban Planning, 216, 104257.\",\n","          \"year\": 2021,\n","          \"doi\": \"10.1016/j.landurbplan.2021.104257\",\n","          \"relationship\": {\n","            \"direction\": {\n","              \"code\": \"DIR_POS\",\n","              \"name\": \"Positive\",\n","              \"definition\": \"Indicator increase leads to outcome increase\"\n","            },\n","            \"effect_size\": \"1.45\",\n","            \"p_value\": \"<0.001\",\n","            \"significance\": {\n","              \"code\": \"SIG_001\",\n","              \"name\": \"p < 0.001\",\n","              \"definition\": \"Highly significant (p < 0.001)\"\n","            }\n","          },\n","          \"study\": {\n","            \"design\": {\n","              \"code\": \"DES_CRS\",\n","              \"name\": \"Cross-Sectional Study\",\n","              \"definition\": \"Observational study analyzing data from a population at a single point in time\"\n","            },\n","            \"sample_size\": 110000,\n","            \"setting\": {\n","              \"code\": \"SET_URB\",\n","              \"name\": \"Urban\",\n","              \"definition\": \"General urban environment\"\n","            },\n","            \"country\": {\n","              \"code\": \"CNT_GLO\",\n","              \"name\": \"Global\",\n","              \"definition\": \"Multi-country or global study\"\n","            }\n","          },\n","          \"quality\": {\n","            \"tier\": {\n","              \"code\": \"TIR_T2\",\n","              \"name\": \"Tier 2: Observational/Correlational\",\n","              \"definition\": \"Evidence derived from cross-sectional or longitudinal studies establishing statistical associations.\"\n","            },\n","            \"confidence\": {\n","              \"code\": \"CON_HIG\",\n","              \"name\": \"High Confidence\",\n","              \"definition\": \"Robust methodology, large sample size, or strong statistical significance.\"\n","            }\n","          }\n","        }\n","      ],\n","      \"measurement\": {\n","        \"method\": {\n","          \"code\": \"MTH_DLV\",\n","          \"name\": \"Deep Learning Vision\",\n","          \"definition\": \"General deep learning computer vision methods\"\n","        },\n","        \"unit\": {\n","          \"code\": \"UNT_PCT\",\n","          \"name\": \"Percentage\",\n","          \"definition\": \"Proportion expressed as 0-100%\"\n","        },\n","        \"data_source\": {\n","          \"code\": \"SRC_GSV\",\n","          \"name\": \"Google Street View\",\n","          \"definition\": \"Street-level imagery from Google Maps\"\n","        }\n","      },\n","      \"target_direction\": {\n","        \"direction\": \"INCREASE\",\n","        \"derivation\": \"The project aims to create a 'barrier-free loop path' and 'strengthen wayfinding'. Evidence shows increasing VAC (sidewalks + lights) significantly increases perceived safety.\"\n","      },\n","      \"rationale\": \"This indicator specifically combines the visual presence of paths, lighting, and benches. It is the most direct metric for the project goal of creating a 'clear, barrier-free loop path' that feels safe and accessible.\"\n","    },\n","    {\n","      \"rank\": 3,\n","      \"indicator\": {\n","        \"code\": \"IND_VPE\",\n","        \"name\": \"Vegetation Permeability Index\",\n","        \"definition\": \"The proportion of non-vegetation volume within the total volume of a defined 3D space, calculated via 3D modeling.\",\n","        \"formula\": \"VP = (Total Volume - Vegetation Volume) / Total Volume * 100\",\n","        \"category\": {\n","          \"code\": \"CAT_CFG\",\n","          \"name\": \"Configurational\",\n","          \"definition\": \"Based on spatial organization, structure, form\"\n","        }\n","      },\n","      \"performance\": {\n","        \"dimension\": {\n","          \"code\": \"PRF_BEH\",\n","          \"name\": \"Use, Accessibility & Safety\",\n","          \"definition\": \"Outcomes related to use patterns and behaviors, including functional convenience/accessibility and perceived safety that shape use.\"\n","        },\n","        \"subdimension\": {\n","          \"code\": \"PRS_SAF_VIS\",\n","          \"name\": \"Performance - Visual Safety\",\n","          \"definition\": \"Measures the perception of safety derived specifically from visual cues within an environment.\"\n","        },\n","        \"outcome_measure\": \"Perceived Safety score (5-point Likert)\",\n","        \"outcome_type\": {\n","          \"code\": \"OUT_SUB\",\n","          \"name\": \"Subjective Rating\",\n","          \"definition\": \"Subjective rating refers to the traditional, human-centric evaluation of 'visual perception' and 'perceived safety.'\"\n","        }\n","      },\n","      \"evidence\": [\n","        {\n","          \"evidence_id\": \"EVD_Li2023_2\",\n","          \"citation\": \"Li, C., Du, C., Ge, S., & Tong, T. (2023). An eye-tracking study on visual perception of vegetation permeability in virtual reality forest exposure. Frontiers in Public Health, 11.\",\n","          \"year\": 2023,\n","          \"doi\": \"10.3389/fpubh.2023.1089423\",\n","          \"relationship\": {\n","            \"direction\": {\n","              \"code\": \"DIR_POS\",\n","              \"name\": \"Positive\",\n","              \"definition\": \"Indicator increase leads to outcome increase\"\n","            },\n","            \"effect_size\": \"0.22\",\n","            \"p_value\": \"<0.01\",\n","            \"significance\": {\n","              \"code\": \"SIG_01\",\n","              \"name\": \"p < 0.01\",\n","              \"definition\": \"Indicates a highly statistically significant result where the probability of observing the data, given that the null hypothesis is true, is less than 1%.\"\n","            }\n","          },\n","          \"study\": {\n","            \"design\": {\n","              \"code\": \"DES_EXP\",\n","              \"name\": \"Experimental Study\",\n","              \"definition\": \"Study involving manipulation of variables in a controlled setting\"\n","            },\n","            \"sample_size\": 46,\n","            \"setting\": {\n","              \"code\": \"SET_FOR\",\n","              \"name\": \"Forest/Woodland\",\n","              \"definition\": \"Forest or woodland environment\"\n","            },\n","            \"country\": {\n","              \"code\": \"CNT_CHN\",\n","              \"name\": \"China\",\n","              \"definition\": \"People's Republic of China\"\n","            }\n","          },\n","          \"quality\": {\n","            \"tier\": {\n","              \"code\": \"TIR_T2\",\n","              \"name\": \"Tier 2: Observational/Correlational\",\n","              \"definition\": \"Evidence derived from cross-sectional or longitudinal studies establishing statistical associations.\"\n","            },\n","            \"confidence\": {\n","              \"code\": \"CON_MED\",\n","              \"name\": \"Medium Confidence\",\n","              \"definition\": \"Acceptable methodology but may have limitations in sample size or generalizability.\"\n","            }\n","          }\n","        }\n","      ],\n","      \"measurement\": {\n","        \"method\": {\n","          \"code\": \"MTH_VOL\",\n","          \"name\": \"Volumetric Analysis\",\n","          \"definition\": \"Analysis of 3D volume\"\n","        },\n","        \"unit\": {\n","          \"code\": \"UNT_PCT\",\n","          \"name\": \"Percentage\",\n","          \"definition\": \"Proportion expressed as 0-100%\"\n","        },\n","        \"data_source\": {\n","          \"code\": \"SRC_SIM\",\n","          \"name\": \"Simulation\",\n","          \"definition\": \"Data generated via computer simulation\"\n","        }\n","      },\n","      \"target_direction\": {\n","        \"direction\": \"INCREASE\",\n","        \"derivation\": \"The brief explicitly constrains the design to 'without creating hidden corners' and 'sightlines at bends'. Increasing permeability ensures greenery (GVI) does not compromise safety.\"\n","      },\n","      \"rationale\": \"This indicator is essential to balance the high GVI target. While GVI promotes walking, low permeability blocks sightlines and reduces safety. IND_VPE ensures the 'Woodland Edge Loop Path' remains safe and visible.\"\n","    },\n","    {\n","      \"rank\": 4,\n","      \"indicator\": {\n","        \"code\": \"IND_WLK_IDX\",\n","        \"name\": \"Walkability Index (Visual)\",\n","        \"definition\": \"The ratio of sidewalk pixels to the sum of sidewalk and driveway pixels in a street view image.\",\n","        \"formula\": \"WI = Sum(Area_sidewalk) / (Sum(Area_sidewalk) + Sum(Area_driveway)) * 100%\",\n","        \"category\": {\n","          \"code\": \"CAT_CMP\",\n","          \"name\": \"Compositional\",\n","          \"definition\": \"Based on element quantity, coverage, proportion\"\n","        }\n","      },\n","      \"performance\": {\n","        \"dimension\": {\n","          \"code\": \"PRF_BEH\",\n","          \"name\": \"Use, Accessibility & Safety\",\n","          \"definition\": \"Outcomes related to use patterns and behaviors, including functional convenience/accessibility and perceived safety that shape use.\"\n","        },\n","        \"subdimension\": {\n","          \"code\": \"PRS_WLK\",\n","          \"name\": \"Walkability Score\",\n","          \"definition\": \"A performance metric assessing the degree to which an environment is friendly to walking.\"\n","        },\n","        \"outcome_measure\": \"Willingness to visit under increasing COVID-19 risk (GLR1 to GLR5)\",\n","        \"outcome_type\": {\n","          \"code\": \"OUT_BEH\",\n","          \"name\": \"Behavioral Observation\",\n","          \"definition\": \"OUT_BEH involves the systematic recording of human actions, movements, and usage patterns within a specific setting.\"\n","        }\n","      },\n","      \"evidence\": [\n","        {\n","          \"evidence_id\": \"EVD_Zhang2024_8\",\n","          \"citation\": \"Zhang, S., Lu, J., Guo, R., & Yang, Y. (2024). Exploring the Relationship Between Visual Perception of the Urban Riverfront Core Landscape Area and the Vitality of Riverfront Road: A Case Study of Guangzhou. Land, 13(12), 2142.\",\n","          \"year\": 2024,\n","          \"doi\": \"10.3390/land13122142\",\n","          \"relationship\": {\n","            \"direction\": {\n","              \"code\": \"DIR_POS\",\n","              \"name\": \"Positive\",\n","              \"definition\": \"Indicator increase leads to outcome increase\"\n","            },\n","            \"effect_size\": \"0.0013\",\n","            \"p_value\": \"0.0000\",\n","            \"significance\": {\n","              \"code\": \"SIG_01\",\n","              \"name\": \"p < 0.01\",\n","              \"definition\": \"Indicates a highly statistically significant result where the probability of observing the data, given that the null hypothesis is true, is less than 1%.\"\n","            }\n","          },\n","          \"study\": {\n","            \"design\": {\n","              \"code\": \"DES_CRS\",\n","              \"name\": \"Cross-Sectional Study\",\n","              \"definition\": \"Observational study analyzing data from a population at a single point in time\"\n","            },\n","            \"sample_size\": 3218,\n","            \"setting\": {\n","              \"code\": \"SET_URB\",\n","              \"name\": \"Urban\",\n","              \"definition\": \"General urban environment\"\n","            },\n","            \"country\": {\n","              \"code\": \"CNT_CHN\",\n","              \"name\": \"China\",\n","              \"definition\": \"People's Republic of China\"\n","            }\n","          },\n","          \"quality\": {\n","            \"tier\": {\n","              \"code\": \"TIR_T2\",\n","              \"name\": \"Tier 2: Observational/Correlational\",\n","              \"definition\": \"Evidence derived from cross-sectional or longitudinal studies establishing statistical associations.\"\n","            },\n","            \"confidence\": {\n","              \"code\": \"CON_HIG\",\n","              \"name\": \"High Confidence\",\n","              \"definition\": \"Robust methodology, large sample size, or strong statistical significance.\"\n","            }\n","          }\n","        }\n","      ],\n","      \"measurement\": {\n","        \"method\": {\n","          \"code\": \"MTH_DLV\",\n","          \"name\": \"Deep Learning Vision\",\n","          \"definition\": \"General deep learning computer vision methods\"\n","        },\n","        \"unit\": {\n","          \"code\": \"UNT_PCT\",\n","          \"name\": \"Percentage\",\n","          \"definition\": \"Proportion expressed as 0-100%\"\n","        },\n","        \"data_source\": {\n","          \"code\": \"SRC_GSV\",\n","          \"name\": \"Google Street View\",\n","          \"definition\": \"Street-level imagery from Google Maps\"\n","        }\n","      },\n","      \"target_direction\": {\n","        \"direction\": \"INCREASE\",\n","        \"derivation\": \"The project aims to 'Create a clear, barrier-free loop path (min 2.5 m)'. Increasing the visual ratio of sidewalk to road/driveway directly supports this functional target.\"\n","      },\n","      \"rationale\": \"This indicator quantifies the dominance of pedestrian space over vehicle/service space. It is critical for the 'Service Node' and 'Entrance Forecourt' where pedestrian-cyclist conflicts and pinch points are identified issues.\"\n","    },\n","    {\n","      \"rank\": 5,\n","      \"indicator\": {\n","        \"code\": \"IND_SVF\",\n","        \"name\": \"Sky View Factor\",\n","        \"definition\": \"Proportion of sky visible from a point\",\n","        \"formula\": \"SVF = (âˆ‘_{i=0}^{n} Ï‰ Â· sky(i) / âˆ‘_{i=0}^{n} Ï‰) * 100%\",\n","        \"category\": {\n","          \"code\": \"CAT_CMP\",\n","          \"name\": \"Compositional\",\n","          \"definition\": \"Based on element quantity, coverage, proportion\"\n","        }\n","      },\n","      \"performance\": {\n","        \"dimension\": {\n","          \"code\": \"PRF_BEH\",\n","          \"name\": \"Use, Accessibility & Safety\",\n","          \"definition\": \"Outcomes related to use patterns and behaviors, including functional convenience/accessibility and perceived safety that shape use.\"\n","        },\n","        \"subdimension\": {\n","          \"code\": \"PRS_WLK\",\n","          \"name\": \"Walkability Score\",\n","          \"definition\": \"A performance metric assessing the degree to which an environment is friendly to walking.\"\n","        },\n","        \"outcome_measure\": \"Walking preference\",\n","        \"outcome_type\": {\n","          \"code\": \"OUT_BEH\",\n","          \"name\": \"Behavioral Observation\",\n","          \"definition\": \"OUT_BEH involves the systematic recording of human actions, movements, and usage patterns within a specific setting.\"\n","        }\n","      },\n","      \"evidence\": [\n","        {\n","          \"evidence_id\": \"EVD_Zou2024_1\",\n","          \"citation\": \"Zou, J., Jiang, H., Ying, W., & Qiu, B. (2024). Scenic Influences on Walking Preferences in Urban Forest Parks from Top-View and Eye-Level Perspectives. Forests, 15(11), 2020.\",\n","          \"year\": 2024,\n","          \"doi\": \"10.3390/f15112020\",\n","          \"relationship\": {\n","            \"direction\": {\n","              \"code\": \"DIR_POS\",\n","              \"name\": \"Positive\",\n","              \"definition\": \"Indicator increase leads to outcome increase\"\n","            },\n","            \"effect_size\": \"0.102\",\n","            \"p_value\": \"0.008\",\n","            \"significance\": {\n","              \"code\": \"SIG_01\",\n","              \"name\": \"p < 0.01\",\n","              \"definition\": \"Indicates a highly statistically significant result where the probability of observing the data, given that the null hypothesis is true, is less than 1%.\"\n","            }\n","          },\n","          \"study\": {\n","            \"design\": {\n","              \"code\": \"DES_CRS\",\n","              \"name\": \"Cross-Sectional Study\",\n","              \"definition\": \"Observational study analyzing data from a population at a single point in time\"\n","            },\n","            \"sample_size\": 395,\n","            \"setting\": {\n","              \"code\": \"SET_PRK\",\n","              \"name\": \"Park\",\n","              \"definition\": \"Urban park setting\"\n","            },\n","            \"country\": {\n","              \"code\": \"CNT_CHN\",\n","              \"name\": \"China\",\n","              \"definition\": \"People's Republic of China\"\n","            }\n","          },\n","          \"quality\": {\n","            \"tier\": {\n","              \"code\": \"TIR_T2\",\n","              \"name\": \"Tier 2: Observational/Correlational\",\n","              \"definition\": \"Evidence derived from cross-sectional or longitudinal studies establishing statistical associations.\"\n","            },\n","            \"confidence\": {\n","              \"code\": \"CON_HIG\",\n","              \"name\": \"High Confidence\",\n","              \"definition\": \"Robust methodology, large sample size, or strong statistical significance.\"\n","            }\n","          }\n","        }\n","      ],\n","      \"measurement\": {\n","        \"method\": {\n","          \"code\": \"MTH_FSH_PRJ\",\n","          \"name\": \"Fisheye Projection\",\n","          \"definition\": \"Analysis using fisheye lens projection\"\n","        },\n","        \"unit\": {\n","          \"code\": \"UNT_RTO\",\n","          \"name\": \"Ratio\",\n","          \"definition\": \"A relationship between two numbers indicating how many times the first number contains the second.\"\n","        },\n","        \"data_source\": {\n","          \"code\": \"SRC_FLD\",\n","          \"name\": \"Field Data\",\n","          \"definition\": \"Data collected directly from the field\"\n","        }\n","      },\n","      \"target_direction\": {\n","        \"direction\": \"INCREASE\",\n","        \"derivation\": \"Evidence suggests a positive link between SVF and walking preference in parks. This balances the need for shade with the need for openness to prevent the 'hidden corners' issue.\"\n","      },\n","      \"rationale\": \"SVF helps balance the 'Shade' constraint with the 'Safety/Visibility' target. While trees are needed for shade, maintaining sufficient Sky View Factor ensures the park does not feel oppressive or unsafe, particularly in the 'Woodland Edge Loop Path'.\"\n","    }\n","  ],\n","  \"indicator_relationships\": [\n","    {\n","      \"indicators\": [\n","        {\n","          \"code\": \"IND_GVI\",\n","          \"name\": \"Green View Index\"\n","        },\n","        {\n","          \"code\": \"IND_VPE\",\n","          \"name\": \"Vegetation Permeability Index\"\n","        }\n","      ],\n","      \"type\": \"SYNERGISTIC\",\n","      \"explanation\": \"While high GVI generally improves walkability, dense vegetation can block sightlines and reduce safety. IND_VPE acts as a quality control for GVI, ensuring that the greenery added for comfort/aesthetics allows for visual permeability, satisfying the safety constraints.\"\n","    },\n","    {\n","      \"indicators\": [\n","        {\n","          \"code\": \"IND_VAC\",\n","          \"name\": \"Visible Accessibility Index\"\n","        },\n","        {\n","          \"code\": \"IND_WLK_IDX\",\n","          \"name\": \"Walkability Index (Visual)\"\n","        }\n","      ],\n","      \"type\": \"SYNERGISTIC\",\n","      \"explanation\": \"Both indicators measure the dominance of pedestrian infrastructure. IND_WLK_IDX focuses on the ratio of path to road (spatial allocation), while IND_VAC includes amenities like lighting and benches (functional support). Together they provide a comprehensive measure of the 'barrier-free loop'.\"\n","    }\n","  ],\n","  \"summary\": {\n","    \"total_indicators\": 5,\n","    \"total_evidence\": 7,\n","    \"key_findings\": [\n","      \"Green View Index (GVI) is the strongest predictor for walking behavior and general attractiveness, but must be carefully managed for safety.\",\n","      \"Visible Accessibility (VAC) and Walkability Index (WLK_IDX) are critical for the specific goal of creating a 'barrier-free loop', directly linking infrastructure visibility to safety.\",\n","      \"Vegetation Permeability (VPE) is a crucial 'check' indicator to ensure the shade/greenery goals do not create the 'hidden corners' warned against in the brief.\"\n","    ],\n","    \"evidence_gaps\": [\n","      \"Direct evidence linking specific wayfinding signage (IND_LEG or similar) to movement efficiency in small parks is limited in the provided set; proxies like VAC and SFI are used instead.\"\n","    ]\n","  }\n","}\n"]}]},{"cell_type":"code","source":["out_dir = Path(CONFIG['output_path'])\n","out_dir.mkdir(parents=True, exist_ok=True)\n","ts = datetime.now().strftime('%Y%m%d_%H%M%S')\n","out_file = out_dir / f'STAGE1_{ts}.json'\n","json.dump(result, open(out_file, 'w', encoding='utf-8'), ensure_ascii=False, indent=2)\n","print(f\"âœ… Saved: {out_file}\")"],"metadata":{"id":"save","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1766621606478,"user_tz":-60,"elapsed":286,"user":{"displayName":"junkai lan","userId":"05837454952170495153"}},"outputId":"7354ec9c-8e90-47e2-d50b-b34a2a6eb18a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Saved: /content/drive/MyDrive/GreenSVC-AI-paper/Outputs/STAGE1_20251225_001327.json\n"]}]}]}